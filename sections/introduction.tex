\section{Introduction}\label{ch:introduction}

Static analysis of computational complexity has long been a central part of algorithm design and computer science as a whole. One way of performing such a static analysis on a program is by means of type-based techniques. Traditionally, soundness properties have pertained to the absence of certain run-time errors, i.e. \textit{well-typed programs do not go wrong} \cite{Milner1978} but  with the advent of behavioral type disciplines, soundness properties that for instance ensure bounds on the resource use of programs have been proved. % If combined with an implementation, i.e. an algorithm that specifies how the rules of a type system are to be used, we may either verify that a specified type based complexity analysis of a program is correct (type-checking), or automate the complexity analysis and infer a complexity bound for a program, if it can be bounded by the type system (type inference).

Research on type systems for computational complexity has originally focused on sequential programs, using a notion of types that can express sizes of terms in a program, referred to as sized types, which have been both formalized and implemented \cite{HofmannAndJost2003,HofmannAndHoffmann2010,HoffmannEtAl2012,LagoGaboardi2012,AvanziniLago2017}. However, there is particularly interest in static complexity analysis of parallel and concurrent computation, following the trend for programs to increase in size, as distributed systems scale better. Moreover, parallel and especially concurrent computation is significantly more difficult to analyze, and so the work on type systems for static complexity analysis has been extended to parallel computation \cite{HoffmannShao2015}, and more recently to the more intricate domain of message-passing processes, using behavioral type disciplines to bound message-passing \cite{BaillotGhyselen2021,BaillotEtAl2021}.

Baillot and Ghyselen \cite{BaillotGhyselen2021} introduce a type system for parallel computational complexity of $\pi$-calculus processes, extended with naturals and pattern matching as a computational model, combining sized types and input/output types to bound synchronizations on channels, and thereby bound the parallel time complexity of a process. Baillot et al. \cite{BaillotEtAl2021} generalize the type system using the more expressive behavioral type discipline usage types \cite{Kobayashi1998,KobayashiEtAl2000}. However, these type systems are quite abstract and build on a notion of sized types that has yet to be implemented in the context of message-passing, and so neither type checking nor type inference has until now been realized for either type system.

In this thesis, we explore the challenges of implementing type checking and type inference for the type system by Baillot and Ghyselen \cite{BaillotGhyselen2021}. An important part of this type system is the concept of indices. That is, arithmetic expressions that may contain index variables that represent unknown sizes, thereby enabling a notion of size polymorphism. Indices appear in sized types, to for instance express the timesteps at which a channel must synchronize, which may depend on the size of a value received on a replicated input. To compute an upper bound on the parallel complexity, a partial order on channel synchronizations is required, represented as index comparisons that we refer to as constraint judgements and read as: \textit{Provided a set of constraints on valuations of index variables, is one index always less than or equal to another?} Many of the challenges that arise for both type checking and type inference are related to either verification or satisfaction of such judgements.%Finally, the type system relies on on a special form of minus that can never give negative results, which breaks many useful mathematical properties.\\

We implement a type checker for the type system by Baillot and Ghyselen. This effort is two-fold: We define algorithmic type rules and show how constraint judgements on linear indices can be verified using integer programming or alternatively be over-approximated as linear programs. The type system makes heavy use of subtyping, which we partially account for using \textit{combined complexities} that are effectively sets of indices with a number of associated functions that enable us to discard indices we can guarantee to be bounded by other indices. Combined complexities have the advantage that we can defer finding a single index representing a least upper bound until a later time, and we can in fact show that the combined complexity of a closed process can always be reduced to a singleton, i.e. a singular complexity bound.

We prove that our type checker is sound with regards to time complexity, and to this effort we prove a subject reduction property. Our soundness results guarantee that the bounds assigned to well-typed processes by our type checker are indeed upper bounds on the parallel complexity. To increase the expressiveness of the type checker, we also show how constraints on monotonic univariate polynomial indices can be reduced to linear constraints.

We also define a type inference algorithm for the type system by Baillot and Ghyselen. We take a constraint based approach akin to that of \cite{HofmannAndJost2003,HofmannAndHoffmann2010,HoffmannEtAl2012,KobayashiEtAl2000,Kobayashi2005,Lhoussaine2004}, where unknown indices are represented by \textit{templates}: linear functions over a set of known index variables with unknown coefficients represented by coefficient variables. Inspired by  Kobayashi et al. \cite{KobayashiEtAl2000}, we first infer simple types, which are then used to infer a constraint satisfaction problem on use-capabilities and subtyping which we then reduce to constraints of the form $\exists\alpha_1,\dots,\alpha_n.\forall i_1,\dots,i_m.C_1\land\cdots\land C_k \implies I \leq J$ where $\alpha_1,\dots,\alpha_n$ are coefficient variables, $i_1,\dots,i_m$ are index variables, $C_1,\dots,C_k$ are inequality constraints on indices and $I$ and $J$ are indices.

We provide a Haskell implementation of our type inference algorithm using the Z3 SMT solver \cite{Z3}. We naively eliminate universal quantifiers by over-approximating our constraints using coefficient-wise inequality constraints. We account for antecedents $C_1,\dots,C_k$ by substitution. For instance, if we can deduce that coefficient $c$ is positive in the constraint $\exists\alpha_1,\dots,\alpha_n.\forall i_1,\dots,i_j,\dots,i_m.K \leq L + ci_j \land C_1 \land \cdots \land C_k \implies I \leq J$, then we can simulate the antecedent by substituting $\frac{K-L}{c} + i_j$ for $i_j$, i.e. $\exists\alpha_1,\dots,\alpha_n.\forall i_1,\dots,i_j,\dots,i_m.C_1\{\frac{K-L}{c} + i_j/i_j\} \land \cdots \land C_k\{\frac{K-L}{c} + i_j/i_j\} \implies I\{\frac{K-L}{c} + i_j/i_j\} \leq J\{\frac{K-L}{c} + i_j/i_j\}$. Using these over-approximations, our implementation is able to infer precise bounds on several processes containing replicated inputs with linear time complexity.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../esop2023"
%%% End:
