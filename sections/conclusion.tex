\section{Conclusion}\label{ch:conclusion}
In this paper, we have explored the challenges of implementing both a type checker and type inference for the type system for parallel complexity of $\pi$-calculus processes by Baillot and Ghyselen \cite{BaillotGhyselen2021}. In this chapter, we first present and discuss our results, after which we discuss limitations of our implementations. Finally, we consider future work, and discuss how some of the limitations may be relaxed.
%
\subsection{Results}
Type checking and type inference are limited by our ability to respectively verify or satisfy constraint judgements. As such judgements are universally quantified over index variables, this becomes non-trivial. We can reduce verification of constraint judgements to linear programming, where a constraint judgement holds if there is no solution to the corresponding linear program. We have also shown that certain polynomial constraint judgements can be reduced to linear constraint judgements, enabling type checking of some processes with polynomial time behavior. We have introduced algorithmic type rules for type checking, and proved their soundness with respect to parallel complexity.\\ %To ensure we maintain the subject reduction property, we introduced combined complexities and the associated function \textit{basis}, such that we effectively defer checks of constraint judgements introduced by parallel composition until a later time. The type checker has been proved sound.\\

Our type inference algorithm performs multiple passes over a program to first infer simple types, which are then used to infer constraints on the variance of input/output types, sizes of naturals, bounds on channel synchronization and complexity bounds. We can reduce such constraints to a set of constraint judgements with existentially quantified variables representing coefficients that when solved provide a bound on the span. These constraints are significantly more difficult to solve than those that emerge for type checking, and so we over-approximate them using naive quantifier elimination. We provide a Haskell implementation based on the Z3 SMT solver.\\

%We have introduced constraint based type inference to the type system by Baillot and Ghyselen, which is inspired by the work of Kobayashi et al. \cite{KobayashiEtAl2000}. To infer types, we do multiple passes over the program to infer different kinds of constraints, whose solution corresponds to a valid typing of the program. To solve the constraints, we reduce them into simple constraints on coefficients that are solved by an off-the-shelf SMT solver. However, we found that by naively generating constraints, we get constraints consisting of nested existential and universal quantifiers that are very difficult to solve even for state-of-the-art SMT solvers. So, to solve these constraints we make a number of over-approximations during reduction of constraints. We implement type inference in Haskell using the Z3 SMT solver to solve constraints.\\

Overall, we find that we can type check many constant and linear time processes and some polynomial time processes. Similarly, we can infer precise bounds on many constant time and some linear time processes in reasonable time. However, both type checking and type inference are limited not only by the expressiveness of complexity bounds, but also by size bounds on naturals, as some encoded algorithms may return naturals with size bounds that exceed their complexity bounds. As our type inference algorithm infers polynomial constraints, we are also limited by the ability to find solutions, which we find to be difficult for many simple processes.

\subsection{Discussion}

During type checking, we limit ourselves to linear indices such that we can reduce constraint judgements to a linear program that can be solved by an algorithm such as the simplex algorithm. We have primarily made this choice for the sake of simplicity, however, tools such as \textit{Gröbner bases} exist that can be used to help solving systems of polynomial equations. Even more generally, existing provers such as the Z3 prover, which utilizes, among other things, Gröbner bases, could be used to solve both linear and some super-linear systems.\\

As for type inference, we are able to infer precise bounds on some constant and linear time servers. We notice that inferred constraint satisfaction problems for servers quickly grow in difficulty based on the number of index variables. Even simple processes with no ticks take significantly longer time to solve, when an extra index variable is introduced. We ascribe this to the polynomial constraints introduced upon instantiating servers, and so it may make sense to consider further over-approximations of substitutions.\\

An interesting observation is that our restriction to linear indices makes us unable to infer bounds on some linear time processes. One such example is that of the Fibonacci number encoding, where we are unable to express size bounds on the \textit{returned} Fibonacci number, which grows according to the Fibonacci sequence, yet we can express the complexity of the server. Although the complexity is not directly affected by the size of this natural, we are thus unable to infer a sized type for the server. As the complexity of a process does not necessarily depend on all size bounds, it may be possible to let some of them be unknown, and thereby relax the restriction.\\

We also notice the importance of antecedents in constraint judgements. When all antecedents are discarded, we are unable to infer bounds on any linear time server. Moreover, we observe that coefficient variables do not take negative valuations unless we simulate antecedents. We believe this is due to our over-approximations of index inequality constraints. That is, we implicitly infer the constraint $\varphi;\Phi\vDash 0 \leq I$ for all indices $I$, which we over-approximate using coefficient-wise inequality constraints, which means all coefficients must be non-negative. This seems to translate to all coefficient variables being non-negative as well. However, when antecedents are simulated, we may substitute a positive term into an index, providing more flexibility to coefficient variable valuations. We believe this is why our simulation of inequality antecedents greatly increases expressiveness of our type inference algorithm.

% type check
%   better ways to reduce (more) polynomial constraints to linear: Hoffmann and Hofmann
%   Gröbner basis for solving polynomial constraint judgements?
% type inference
%   what can we infer bounds on: Constant time processes, some linear time processes; Processes with different span and work!
%   what can we not infer bounds on: fib; not only a question of complexity but also size of outputs (non-linear); What can we do about it? - better use of index variables ..


%   The importance of antecedents
%   Consequences of our over-approximations:  0 <= I means all coefficients in I are non-negative!

\subsection{Future work}
We have introduced algorithmic type rules for the type system by Baillot and Ghyselen \cite{BaillotGhyselen2021}, enabling us to implement a type checker that given some type environment and process, can verify if process is well-typed under the environment, and thereby provide us a bound on the parallel complexity. As such, a natural next step is to implement the type checker in for instance Haskell.\\

We have primarily limited ourselves to linear indices, and thereby linear complexity bounds, as the corresponding constraint judgements are then simpler to verify or satisfy. It may be worthwhile to explore how this restriction may be relaxed. Hofmann and Hoffmann \cite{HofmannAndHoffmann2010} and Hoffmann et al. \cite{HoffmannEtAl2012}, show how linear constraints can be derived from polynomial bounds, by representing polynomials as sums of binomial coefficients. However, this is in the setting of first-order functional programs, and so it may be interesting to see if this method can be applied to message-passing processes.\\

Our type inference algorithm for parallel complexity of $\pi$-calculus processes provides correct bounds on the parallel complexity of the processes we have tried (when a bound can be inferred in reasonable time). However, we have yet to formally prove its correctness. In particular, we are interested in proving that our algorithm always infers principal typings. We expect this property to be quite straightforward to prove, as our inference rules are based on the type rules. One exception to this is our treatment of time invariance.\\

% Better support for lower-bounds: antecedents; I = 0, can be solved in the same way as I >= 1 with proper index variable use !!

In this thesis, we have limited ourselves to the type system for parallel complexity by Baillot and Ghyselen \cite{BaillotGhyselen2021}. However, the usage-based generalization of the type system provided by Baillot et al. \cite{BaillotEtAl2021} increases the expressiveness and precision. Usages allow for more precise description of the behavior of channels, for instance making processes with some forms of indeterministic communication typable. Usages are well-suited for inference, and as this type system shares many similarities with the type system by Baillot and Ghyselen, it may be interesting to see if our type inference algorithm can be extended to usages. Constraint-based inference of usage types have been studied previously, and judging from this work, we expect usage reliability to be the main challenge due to universal quantification over index variables \cite{KobayashiEtAl2000, Kobayashi2005}.

% implementation of type check
% extension of type inference to polynomial bounds alá Hoffmann and Hofmann and Hoffmann et al. (their representation of polynomials)
% prove soundness of type inference
% Extending type inference to usages
% Better support for lower-bounds: antecedents; I = 0, can be solved in the same way as I >= 1 with proper index variable use !!
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../esop2023"
%%% End:
