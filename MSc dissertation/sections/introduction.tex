% Introduktion:
% Motivation til typesystemer for tidskompleksitet
%   Hvad eksisterer lige nu?
%       Sekventielle er udforsket og implementeret
%       Baillot og ghyselen samt baillot et al. har lavet sunde typesystemer for parallel kompleksitet af pi-kalkylen
%       Typesystemer for parallel kompleksitet af pi-kalkylen er ikke implementeret endnu
% Hvorfor er parallel kompleksitet (med message-passing) sværere at implementere; Hvilke udfordringer er der ved typetjek for sådanne typesystemer?
%   Constraint judgements
%   Subtyping
%   Monus
%   
% Vores contributions
%    En typetjekker for Baillot og Ghyselen der bruger combined complexities til at implementere subtyping
%    Vi har bevist at typetjekkeren er sund ift. tidskompleksitet
%    Vi har bevist at judgements på constraints som i Baillot og Ghyselen og Baillot et al. er uafgørbare for polynomielle constraints ved reduktion fra Hilberts 10ende problem.
%    Vi har vist hvordan lineære constraint judgements kan løses som integer programs når vi er forsigtige med brugen af monus.
%    -- ting med typetjekker for baillot et al kommer når vi har det :)

% Related work:
%
\chapter{Introduction}\label{ch:introduction}
Static analysis of computational complexity has long been a central part of algorithm design and computer science as a whole. Computational complexity may refer to various resources that are used during the execution of a program such as time or memory (space). Ensuring that a program uses only a bounded number of resources may be vital to its execution, depending on for instance the hardware and responsiveness. As such, analyzing the complexity of a program before integrating it into some critical environment is of high importance. 

\section{Complexity analysis and type systems}
One way of performing such a static analysis on a program is to define a set of type rules that the program must adhere to, collectively referred to as a type system. If a program satisfies the rules of a type system, under some context that typically assigns types to variables in the program, we say it is \textit{well-typed}. Here, a type typically specifies properties with respect to the values some variable or expression may take during execution of a program. Type systems have the advantage that they are based on formal methods, and are therefore often proved sound. Traditionally, soundness properties have pertained to the absence of certain run-time errors, i.e. \textit{well-typed programs do not go wrong} \cite{Milner1978}. More recently, with the advent of behavioral type disciplines, soundness properties that for instance ensure bounds on the resource use of programs have been proved. If combined with an implementation, i.e. an algorithm that specifies how the rules of a type system are to be used, we may either verify that a specified type based complexity analysis of a program is correct (type-checking), or automate the complexity analysis and infer a complexity bound for a program, if it can be bounded by the type system (type inference). \\

Research on type systems for computational complexity has originally focused on sequential programs, using a notion of types that can express sizes of terms in a program, referred to as sized types, which have been both formalized and implemented \cite{HofmannAndJost2003,HofmannAndHoffmann2010,HoffmannEtAl2012,LagoGaboardi2012,AvanziniLago2017}. However, there is particularly interest in static complexity analysis of parallel and concurrent computation, following the trend for programs to increase in size, as distributed systems scale better. Moreover, parallel and especially concurrent computation is significantly more difficult to analyze, and so the work on type systems for static complexity analysis has been extended to parallel computation \cite{HoffmannShao2015}, and more recently to the more intricate domain of message-passing processes, using behavioral type disciplines to bound message-passing \cite{BaillotGhyselen2021,BaillotEtAl2021}.\\ 

Baillot and Ghyselen \cite{BaillotGhyselen2021} introduce a type system for parallel computational complexity of $\pi$-calculus processes, extended with naturals and pattern matching as a computational model, combining sized types and input/output types to bound synchronizations on channels, and thereby bound the parallel time complexity of a process. Baillot et al. \cite{BaillotEtAl2021} generalize the type system using the more expressive behavioral type discipline usage types \cite{Kobayashi1998,KobayashiEtAl2000}. However, these type systems are quite abstract and build on a notion of sized types that has yet to be implemented in the context of message-passing, and so neither type checking nor type inference has until now been realized for either type system.

\section{Our contributions}
In this thesis, we explore the challenges of implementing type checking and type inference for the type system by Baillot and Ghyselen \cite{BaillotGhyselen2021}. An important part of this type system is the concept of indices. That is, arithmetic expressions that may contain index variables that represent unknown sizes, thereby enabling a notion of size polymorphism. Indices appear in sized types, to for instance express the timesteps at which a channel must synchronize, which may depend on the size of a value received on a replicated input. To compute an upper bound on the parallel complexity, a partial order on channel synchronizations is required, represented as index comparisons that we refer to as constraint judgements and read as: \textit{Provided a set of constraints on valuations of index variables, is one index always less than or equal to another?} Many of the challenges that arise for both type checking and type inference are related to either verification or satisfaction of such judgements.\\%Finally, the type system relies on on a special form of minus that can never give negative results, which breaks many useful mathematical properties.\\

We implement a type checker for the type system by Baillot and Ghyselen. This effort is two-fold: We define algorithmic type rules and show how constraint judgements on linear indices can be verified using integer programming or alternatively be over-approximated as linear programs. The type system makes heavy use of subtyping, which we partially account for using \textit{combined complexities} that are effectively sets of indices with a number of associated functions that enable us to discard indices we can guarantee to be bounded by other indices. Combined complexities have the advantage that we can defer finding a single index representing a least upper bound until a later time, and we can in fact show that the combined complexity of a closed process can always be reduced to a singleton, i.e. a singular complexity bound.\\

We prove that our type checker is sound with regards to time complexity, and to this effort we prove a subject reduction property. Our soundness results guarantee that the bounds assigned to well-typed processes by our type checker are indeed upper bounds on the parallel complexity. To increase the expressiveness of the type checker, we also show how constraints on monotonic univariate polynomial indices can be reduced to linear constraints.\\

We also define a type inference algorithm for the type system by Baillot and Ghyselen. We take a constraint based approach akin to that of \cite{HofmannAndJost2003,HofmannAndHoffmann2010,HoffmannEtAl2012,KobayashiEtAl2000,Kobayashi2005,Lhoussaine2004}, where unknown indices are represented by \textit{templates}: linear functions over a set of known index variables with unknown coefficients represented by coefficient variables. Inspired by  Kobayashi et al. \cite{KobayashiEtAl2000}, we first infer simple types, which are then used to infer a constraint satisfaction problem on use-capabilities and subtyping which we then reduce to constraints of the form $\exists\alpha_1,\dots,\alpha_n.\forall i_1,\dots,i_m.C_1\land\cdots\land C_k \implies I \leq J$ where $\alpha_1,\dots,\alpha_n$ are coefficient variables, $i_1,\dots,i_m$ are index variables, $C_1,\dots,C_k$ are inequality constraints on indices and $I$ and $J$ are indices.\\

We provide a Haskell implementation of our type inference algorithm using the Z3 SMT solver \cite{Z3}. We naively eliminate universal quantifiers by over-approximating our constraints using coefficient-wise inequality constraints. We account for antecedents $C_1,\dots,C_k$ by substitution. For instance, if we can deduce that coefficient $c$ is positive in the constraint $\exists\alpha_1,\dots,\alpha_n.\forall i_1,\dots,i_j,\dots,i_m.K \leq L + ci_j \land C_1 \land \cdots \land C_k \implies I \leq J$, then we can simulate the antecedent by substituting $\frac{K-L}{c} + i_j$ for $i_j$, i.e. $\exists\alpha_1,\dots,\alpha_n.\forall i_1,\dots,i_j,\dots,i_m.C_1\{\frac{K-L}{c} + i_j/i_j\} \land \cdots \land C_k\{\frac{K-L}{c} + i_j/i_j\} \implies I\{\frac{K-L}{c} + i_j/i_j\} \leq J\{\frac{K-L}{c} + i_j/i_j\}$. Using these over-approximations, our implementation is able to infer precise bounds on several processes containing replicated inputs with linear time complexity.

%constraints on coefficients. Once all coefficient constraints are collected, they are passed to a SMT solver and a solution is possibly found. The solution is a model assigning values to coefficient variables occuring in the sized types of Baillot and Ghyselen. By limiting ourselves to linear indices, we can always know the structure of an index and thus know which index variables to introduce. We are forced to make a number of over-approximations during the reduction of constraints such as quantifier elimination, such that the SMT solver can find a model of the constraints.\\

% This thesis is structured as follows: In Section \ref{sec:relatedwork} we discuss related work, and in Chapter 2 we define the variant of the $\pi$-calculus we will use throughout this thesis and present the notion of parallel complexity used in the type systems by Baillot and Ghyselen \cite{BaillotGhyselen2021} and Baillot et al. \cite{BaillotEtAl2021}. In Chapter 3 we handle the important concept of constraint judgements which are central both in the type system of Baillot and Ghyselen and the type system of Baillot et al. This chapter aims to give both a formal and an intuitive understanding of constraint judgements, and how they may be verified. An overview of the type system of Baillot and Ghyselen and more details on how they use constraints are then given in Chapter 4. Then, in Chapter 5 we present algorithmic type rules for the type system by Baillot and Ghyselen, as well as show the algorithmic type system is sound, before finally showing examples of how processes can be type checked. In Chapter 6 we tackle the harder problem of automating the typing of a process, such that one can infer the computational complexity of a process. We also describe our Haskell implementation of type inference. Finally, in Chapter 7 we conclude and discuss future work.

\section{Related work}\label{sec:relatedwork}
Hughes et al. \cite{HughesEtAl1996} introduce the concept of sized types in the domain of reactive systems, to prove the absence of deadlocks and non-termination in embedded programs. This notion of sized types statically bounds the maximum size that variables may take during run-time using linear functions over size variables (which they refer to as \textit{size indices}). Since the introduction of sized types, several pieces of work regarding computational complexity have been made based on these. Hofmann and Jost \cite{HofmannAndJost2003} extend the use of sized types to analyzing the space complexity of sequential programs. To infer the space complexity of a program, they set up so-called templates for unknown sizes that are sums of terms for universally quantified size variables with unknown coefficients represented as existentially quantified variables. These templates must satisfy certain constraints imposed by the typing of a program. By restricting themselves to linear bounds, they then find a solution to said constraints using linear programming, thus inferring size bounds.\\

Hoffmann and Hofmann \cite{HofmannAndHoffmann2010} introduce a type system that utilizes a potential-based amortized analysis to infer resource bounds on sequential programs. In addition to using amortized analysis to infer tighter bounds, they are also able to type programs with certain polynomial bounds by deriving linear constraints on the coefficients of the polynomials. They use a unique representation of polynomials using binomial coefficients, which have a number of advantages, increasing the expressiveness of the type system. One of their limitations regarding polynomials, is that they can only infer sums of univariate polynomials, which means that a polynomial bound such as $nm$ must be overestimated by $n^2 + m^2$. As they derive linear constraints, they are able to infer types in much the same way as Hofmann and Jost using linear programming. In addition to implementing type inference, they also prove that their analysis is sound. Hoffmann et al. \cite{HoffmannEtAl2012} show how this can be extended to multivariate polynomials, and prove that the system is sound.\\

Dal Lago and Gaboardi \cite{DalLagoGaboardi2011} present a family of type systems based on dependent types and linear logic. As the previously mentioned type systems, they also use a notion of sized types based on indices. They rely on an underlying logic of indices, that has partly unspecified function symbols. However, they require that the function symbols of indices include the addition and monus operators. This is not unlike the type systems by both Baillot and Ghyselen \cite{BaillotGhyselen2021} as well as Baillot et al. \cite{BaillotEtAl2021}. Dal Lago and Gaboardi prove soundness of the family of type systems as well as \textit{relative completeness}. They only prove relative completeness as the actual completeness of any type system in the family depends on the completeness of the underlying logic of indices of that type system. As such, they also provide no implementation of type checking nor type inference. Instead, they discuss the undecidability of type checking in the general sense, which is the case due to semantic assumptions of indices as well as subtyping judgements.\\

%Avancini and Dal Lago?

With the continuous rise in popularity of distributed systems and parallel programs, work has also been done on complexity analysis of parallel programs. Of such is the work by Hoffmann and Shao \cite{HoffmannShao2015}, who introduce the first type system for automatic analysis for deriving complexity bounds on parallel first-order functional programs. They analyze both the work and span of a program using two different methods. For analyzing the work, they simply use the method described by Hoffmann et al., however, for analyzing the span they use a novel method. The main challenge in this work is to extend the potential method to parallel programs, while ensuring the type system is composable and sound. As for some of the previously mentioned type systems, they reduce the problem of type inference to a linear programming problem that they solve to obtain types for the program. However, this type system does not allow parallel subprograms to pass messages to each other, and so they cannot communicate.\\

A type system that differs widely from the previously mentioned ones is introduced by Das et al. \cite{DasEtAl2018}. They introduce a type system for parallel complexity of the $\pi$-calculus based on session types by extending them with the \textit{temporal modalities} \textit{next}, \textit{always}, and \textit{eventually}. By using session types, they naturally consider the sessions between processes and not the processes directly. This has both advantages and disadvantages in that they may describe useful information between communications of processes, but less information about the program as a whole. However, with the rise in distributed systems, it may be beneficial to focus on the protocols between processes. However, this type system does not use sized types, and so only constant time complexity bounds can be expressed.\\

A central notion in the type system by Baillot et al. is that of \textit{usages}. The idea of usages has roots in work by Kobayashi \cite{Kobayashi1998}, where usages are used to partially ensure deadlock-freedom in the $\pi$-calculus. Sumii and Kobayashi \cite{SumiiKobayashi1998} refine the definition of usages and present a type system for deadlock-freedom. When considering deadlock freedom analysis and complexity analysis, we are interested in similar program properties as both consider the run-time of programs. Usages describe the behavior of channels by indicating how they are used for input and output in parallel and sequentially. A key concept of usages is that of obligations and capabilities which describe when a channel is ready to communicate and when communication may succeed, respectively. Kobayashi et al. \cite{KobayashiEtAl2000} introduce a type inference algorithm for the type system. To do this, they introduce a generalization of usages as well as a subusage relation. They take a constraint based approach to type inference, inferring constraint satisfaction problems that have solutions that match each possible typing of a process.\\

A recurring theme for many of the aforementioned type systems based on sized types is that of their choice of underlying logic for indices. Some of the type systems specify a specific logic (e.g. \cite{HughesEtAl1996,HofmannAndJost2003,HofmannAndHoffmann2010,HoffmannEtAl2012}), while others abstain from specifying one (e.g. \cite{BaillotGhyselen2021,BaillotEtAl2021,DalLagoGaboardi2011}). For the latter, completeness is relative to the choice of logic. One such possible choice of logic is that of Presburger arithmetic \cite{PresburgerArithmetic}. Presburger arithmetic has the advantage that it is consistent, complete, and decidable, and so it is always possible to decide if a given statement can be derived from its axioms or not. However, to obtain such properties, Presburger arithmetic only allows very specific operations consisting of addition and equality. As such, it is not possible to express neither subtraction nor multiplication, which is very restrictive in the domain of complexity analysis. Additionally, the worst-case complexity of the decision problem of Presburger arithmetic is at least doubly exponential, making it impractical to use for a real implementation of a type checker.\\

This thesis is structured as follows: In Chapter \ref{ch:picalc}, we briefly present the variant of the $\pi$-calculus and the notion of parallel complexity used in the type systems by Baillot and Ghyselen \cite{BaillotGhyselen2021} and Baillot et al. \cite{BaillotEtAl2021}. In Chapter \ref{ch:bgts}, we discuss sized types and provide an overview of the type system by Baillot and Ghyselen, aiming to establish familiarity with these topics. In Chapter \ref{ch:typecheck}, we define a type checker for this type system, first presenting algorithmic type rules and then showing how premises can be verified using integer programming. We prove that our algorithmic type rules are sound with respect to parallel complexity. In Chapter \ref{ch:timeinference}, we define a type inference algorithm for the type system, automating parallel complexity analysis of message-passing processes. We also provide a Haskell implementation of our algorithm. Finally, we conclude and discuss future work in Chapter \ref{ch:conclusion}.


%(introduktion af sized types)
%Hughes et al. - Proving the correctness of reacive systems using sized types
%https://dl.acm.org/doi/pdf/10.1145/237721.240882
%
%
%Hofmann and Jost - Static Prediction of Heap Space Usage for First-Order Functional Programs
%https://dl-acm-org.zorac.aub.aau.dk/doi/pdf/10.1145/640128.604148
%
%Hoffmann and Hofmann - Amortized Resource Analysis with Polynomial Potential
%https://www.cs.cmu.edu/~janh/assets/pdf/HoffmannH10.tr.pdf
%
%(Hofmann and Hoffmann - Amortized Resource Analysis with Polymorphic Recursion and Partial %Big-Step Operational Semantics)
%https://link.springer.com/content/pdf/10.1007/978-3-642-17164-2_13.pdf
%
%Hoffmann et al. - Multivariate Amortized Resource Analysis
%https://www.tcs.ifi.lmu.de/mitarbeiter/martin-hofmann/publikationen-pdfs/c60-multivariateamortized%resourceanalysis.pdf
%
%Hoffmann and Shao - Automatic Static Cost Analysis for Parallel Programs
%https://link.springer.com/content/pdf/10.1007/978-3-662-46669-8_6.pdf
%No message-passing; parallel subprograms cannot communicate
%
%kobayashi inferens af usages
%Kobayashi et al. - An implicitly-typed deadlock-free process calculus

% I modsætning til Hoffmann og Shao samt Kobayashi, så har vi constraint judgements, da vi arbejder med message passing. Vi arbejder derfor under nestede universal og existential quantifiers (grundet message-passing)

%Presburger arithmetic?